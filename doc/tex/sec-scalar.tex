
As per the RISC-V Cryptographic Extensions Task Group charter:
``{\em The committee will also make ISA extension proposals for lightweight
scalar instructions for 32 and 64 bit machines that improve the performance
and reduce the code size required for software execution of common algorithms
like AES and SHA and lightweight algorithms like PRESENT and GOST}".

\bigskip

For context, some these instructions have been developed based on academic
work at the University of Bristol as part of the XCrypto project
\cite{MPP:19},
and work by
Paris Telecom on acceleration of lightweight block ciphers
\cite{TGMGD:19}.

% ============================================================================

\subsection{Shared Bitmanip Extension Functionality}

Many of the primitive operations used in symmetric key cryptography
and cryptographic hash functions are well supported by the
RISC-V Bitmanip \cite{riscv:bitmanip:repo} extension
\footnote{
At the time of writing, the Bitmanip extension is still undergoing
standardisation.
Please refer to the bitmanip draft specification
\cite{riscv:bitmanip:draft}
directly for the
latest information, as it may be slightly ahead of what is described
here.
}.
We propose that the scalar cryptographic extension {\em reuse} a
subset of the instructions from the Bitmanip extension directly.
Specifically, this would mean that
a core implementing
{\em either}
the scalar cryptographic extensions,
{\em or}
the bitmanip extension,
{\em or}
both,
would be able to depend on the existance of these instructions.

The following subsections give the assembly syntax of instructions
proposed for inclusion in the scalar crypto extension, along with a
set of use-cases for common algorithms or primitive operations.
For information on the semantics of the instructions, we refer directly
to the bitmanip draft specification.

\subsubsection{Rotations}

\begin{isa}
RV32, RV64:
    ror    rd, rs1, rs2
    rol    rd, rs1, rs2
    rori   rd, rs1, imm

RV64 only:
    rorw   rd, rs1, rs2
    rolw   rd, rs1, rs2
    roriw  rd, rs1, imm
\end{isa}

See \cite[Section 3.1.1]{riscv:bitmanip:draft} for exact details of
these instructions.
Standard bitwise rotation is a primitive operation in many block ciphers and
hash functions.
It particularly features in the ARX (Add,Rotate,Xor) class of
block ciphers
\footnote{\url{https://www.cosic.esat.kuleuven.be/ecrypt/courses/albena11/slides/nicky_mouha_arx-slides.pdf}}.

\begin{isa}
RV32, RV64:
    fsl   rd, rs1, rs3, rs2
    fsr   rd, rs1, rs3, rs2
    fsri  rd, rs1, rs3, imm

RV64 only:
    fslw  rd, rs1, rs3, rs2
    fsrw  rd, rs1, rs3, rs2
    fsriw rd, rs1, rs3, imm
\end{isa}

See \cite[Section 2.9.3]{riscv:bitmanip:draft} for exact details of
these instructions.
The {\em funnel shift} instructions create a $2*XLEN$ word by
concatenating {\tt rs1} and {\tt rs3}, which is then
left/right rotate shifted by the ammount in {\tt imm}/{\tt rs2}.
These are useful for implementing double-width rotations.

\todo{Useful for: SHA3/SHA512 on RV32. 128 bit rotations aren't common, so
possibly only recommend the RV32 instructions?}


\subsubsection{Other Permutations: {\tt grev} and {\tt shfl}}

\begin{isa}
RV32, RV64:
    grev rd, rs1, rs2
    grevi rd, rs1, imm

RV64 only:
    grevw rd, rs1, rs2
    greviw rd, rs1, imm
\end{isa}

The Generalized Reverse ({\tt grev*}) instructions can be used for 
``{\em byte-order swap, bitwise reversal, short-order-swap,
word-order-swap (RV64), nibble-order swap, bitwise reversal in a byte}".
These operations are useful for various permutation operations
needed either by block ciphers and hash-functions directly, or for
endianness correction of data.
Endianness correction is important because
cryptography often occurs in the context of communication, which requires
standardised endianness which may be different from the natural machine
endinaness.

\todo{Specific use-cases for grev.}

\begin{isa}
RV32, RV64:
    shfl    rd, rs1, rs2
    unshfl  rd, rs1, rs2
    shfli   rd, rs1, rs2
    unshfli rd, rs1, rs2

RV64:
    shflw   rd, rs1, rs2
    unshflw rd, rs1, rs2
\end{isa}

The generalized shuffle instructions are useful for implementing
generic bit permutation operations.
Algorithms such as 
DES \footnote{
One might reasonably argue that given the heritage of DES, it's support
shouldn't really be any sort of consideration for a forward looking
ISA like RISC-V.
}
and
PRESENT\cite{block:present} with
irregular / odd permutations are most-likely to benefit from this
instruction.

\todo{More research needed on specific algorithms / use-cases for
these instructions. They are included as ``hypothetically useful"
at the moment.}

\subsubsection{Carryless Multiply}

\begin{isa}
RV32, RV64:
    clmul rd, rs1, rs2
    clmulh rd, rs1, rs2
    clmulr rd, rs1, rs2

RV64 only:
    clmulw rd, rs1, rs2
    clmulhw rd, rs1, rs2
    clmulrw rd, rs1, rs2
\end{isa}

See \cite[Section 2.6]{riscv:bitmanip:draft} for exact details of
this instruction.
As is mentioned there, obvious cryptographic use-cases for carryless
multiply are for Galois Counter Mode (GCM) block cipher operations
\footnote{\url{https://en.wikipedia.org/wiki/Galois/Counter_Mode}}.
GCM is recommended by NIST as a block cipher mode of operation
\cite{nist:gcm}.

\subsubsection{Conditional Move}

\begin{isa}
RV32, RV64:
    cmov rd, rs2, rs1, rs3
\end{isa}

See \cite[Section 2.9.2]{riscv:bitmanip:draft} for exact details of
this instruction.
Conditional move is useful for implementing constant-time cryptographic
code and avoiding control flow changes.

\subsubsection{Logic With Negate}

\begin{isa}
RV32, RV64:
    andn rd, rs1, rs2
     orn rd, rs1, rs2
    xorn rd, rs1, rs2
\end{isa}

See \cite[Section 2.1.3]{riscv:bitmanip:draft} for exact details of
these instructions.
These instructions are useful inside hash functions, block ciphers and
for implementing software based side-channel countermeasures like masking.

\todo{Useful for: SHA3 / SHA2 / Masking}

\subsubsection{Packing}

\begin{isa}
RV32, RV64: 
    pack   rd, rs1, rs2
    packu  rd, rs1, rs2
    packh  rd, rs1, rs2

RV64: 
    packw  rd, rs1, rs2
    packuw rd, rs1, rs2
\end{isa}

See \cite[Section 2.1.4]{riscv:bitmanip:draft} for exact details of
these instructions.
Some lightweight block ciphers (e.g. PRINCE \cite{block:prince}) use
sub-word data types in their primitives.
The bitmanip pack instructions are useful for performing rotations on
16-bit data elements.
They are also useful for re-arranging halfwords within words, and
generally getting data into the right shape prior to applying transforms.

\todo{Concrete list of use-cases.}


% ============================================================================

\subsection{LUT4 Instruction}

\begin{isa}
RV32, RV64:
    lut4    rd, rs1, rs2        // Variant 1
    lut4    rd, rs1, rs2 rs3    // Variant 2
\end{isa}

\begin{lstlisting}[language=c]
// C code for lut4 variant 1 on RV32.
uint32_t lut4_rv32_v1 (uint32_t rd, uint32_t rs1, uint32_t rs2) {
    uint32_t result = 0;
    uint64_t lut    = (((uint64_t)rs1) << 32) | rs2;
    for(int i = 0; i < XLEN;  i += 4) {
        uint32_t in     = ((rd  >>  i) & 0xF) << 2;
        uint64_t toadd  = ((lut >> in) & 0xF) << i;
        result         |= toadd;
    }
    return result;
}
\end{lstlisting}

The {\tt lut4} instruction implements a 4-bit lookup table operation
on every nibble in a source word.
The lookup table is constructed by concatenating two 32-bit words.
On RV32, two XLEN registers are concatenated to form the LUT.
On RV64, the low 32-bits of two XLEN registers are concatenated to form
the LUT.
The instruction is extremely useful for any lightweight block-cipher
which uses a 4-bit SBox.
A comprehensive list and assessment of such ciphers can be found
in \cite{TGMGD:19}.

Two variants are suggested on the assumption that only one variant is
proposed for standardisation:
\begin{itemize}
\item Variant 1: Concatenate {\tt rs1} and {\tt rs2} to form the LUT.
    Use {\tt rd} as a source/destination register.
    The contents of {\tt rd} is chunked into nibbles, which are then
    used as inputs to the lut. The corresponding nibble is replaced
    with the output of the lut and written back to {\tt rd}.
\item Variant 2: Identical to variant 1, but without the read/overwrite
    semantics for {\tt rd}. Input to the lut is taken from {\tt rs3}
    and the output is written to {\tt rd}.
\end{itemize}
Variant 1 is obviously more efficient in terms of encoding space.
Variant 2 has the advantage from a side-channel perspective
of not over-writing it's source register with the result.
This is useful as it avoids implicit hamming distance leakage in
a corrolation power analysis (CPA) context. This could be mitigated
on a micro-architectural level however
\footnote{
    How best to support software side-channel countermeasures at the
    ISA level of abstraction is a non-trivial open question/problem.
}.

% ============================================================================

\subsection{Multi-precision Arithmetic}

\todo{}

% ============================================================================

\subsection{Lightweight AES Acceleration}

\todo{}

% ============================================================================

\subsection{Lightweight SHA2 Acceleration}

\begin{isa}
RV32, RV64:
    ssha256.s0 rd, rs1 : rd = ror32(rs1, 7) ^ ror32(rs1, 18) ^ srl32(rs1, 3)
    ssha256.s1 rd, rs1 : rd = ror32(rs1,17) ^ ror32(rs1, 19) ^ srl32(rs1,10)
    ssha256.s2 rd, rs1 : rd = ror32(rs1, 2) ^ ror32(rs1, 13) ^ ror32(rs1,22)
    ssha256.s3 rd, rs1 : rd = ror32(rs1, 6) ^ ror32(rs1, 11) ^ ror32(rs1,25)
\end{isa}

The {\tt ssha256.sX}
instructions implement the core of the four sigma and sum functions used in
the SHA256 hash function \cite[Section 4.1.2]{nist:fips:180:4}.
These operations will be supported for a both RV32 and RV64 targets.
For RV32, the entire XLEN source register is operated on.
For RV64, the low 32-bits of the XLEN register are read and operated on,
with the result zero extended to XLEN bits.
Though named for SHA256, the instructions work for both the
SHA-224 and SHA-256 parameterisations as described in
\cite{nist:fips:180:4}.


\begin{isa}
RV64:
    ssha512.s0 rd, rs1 : rd = ror64(rs1, 1) ^ ror64(rs1,  8) ^ srl64(rs1, 7)
    ssha512.s1 rd, rs1 : rd = ror64(rs1,19) ^ ror64(rs1, 61) ^ srl64(rs1, 6)
    ssha512.s2 rd, rs1 : rd = ror64(rs1,28) ^ ror64(rs1, 34) ^ ror64(rs1,39)
    ssha512.s3 rd, rs1 : rd = ror64(rs1,14) ^ ror64(rs1, 18) ^ ror64(rs1,41)
\end{isa}

The {\tt ssha512.sX}
instructions implement the core of the four sigma and sum functions used in
the SHA512 hash function \cite[Section 4.1.3]{nist:fips:180:4}.
These operations will be supported for RV64 targets only.
Though named for the SHA-512 parameterisation, the instructions
can be used for all of the SHA-384, SHA-512, SHA-512/224 and SHA-512/256
parameterisations as dscribed in \cite{nist:fips:180:4}.

\note{
The remaining two core functions which make up the SHA256/512
hash functions are the $Ch$ and $Maj$ functions:
\begin{itemize}
\item \lstinline{Ch(x,y,z)  = (x & y) ^ (~x & z)}
\item \lstinline{Maj(x,y,z) = (x & y) ^ ( x & z) ^ ( y & z )}
\end{itemize}
As ternary functions, they are much too expensive in terms of
opcode space to consider for inclusion as dedicated instructions for
such a specialist use case.
They are amenable however to macro-op fusion on cores which implement it.
}

\todo{
These instructions give a
$\approx 1.8x$ performance improvement
and
$\approx 0.6x$ static code size improvment
to a vanilla SHA256 implementation on RV32.
This is based on the work for \cite{MPP:19}, which blends results
from other experimental instructions.
A dedicated benchmark for investigating the effect of just these instructions
for the standardisation process will be needed.
}

% ============================================================================

\subsection{Lightweight SHA3 Acceleration}

The SHA3 secure hash function \cite{nist:fips:202} is based on
the KECCAK-P family of permutations.
SHA3 is notably slower than SHA2 when implemented in software.
It also has a large state size (1600 bits) which is very irregularly
accessed, making it difficult to accelerate
the core {\em compute} operations as part of a scalar CPU pipeline.
We distinguish between {\em compute} operations (which modify the
round function state) and {\em address} operations (which calculate
indexes into the round function state) when motivating these instructions.

The core operations of the KECCAK-P round function are rotations
and XORs, which are already well supported by the RISC-V
base and Bitmanip architectures.
The round function state is accessed as a $5*5$ array of
64-bit words.
All indexes into the state array are generated by a function:
\lstinline{index(x,y) = (x % 5) + 5 * (y % 5)}.

When developing lightweight accelerator instructions for SHA3, we
consider two broad implementation options:
\begin{itemize}
\item Loop unrolled: Here, all of the loops of the round function are
    unrolled, meaning that all variations of the \lstinline{index}
    function are computed at compile time, and are emitted as immediate
    offsets to load and store instructions.
\item Loop rolled-up: The loops are not unrolled, and the
    \lstinline{index} functions are re-computed on every loop iteration.
\end{itemize}

\begin{isa}
RV32, RV64:
    ssha3.xy rd, rs1, rs2 : rd = (( rs1    % 5) + 5(           rs2 % 5)) << 3
    ssha3.x1 rd, rs1, rs2 : rd = (((rs1+1) % 5) + 5(           rs2 % 5)) << 3
    ssha3.x2 rd, rs1, rs2 : rd = (((rs1+2) % 5) + 5(           rs2 % 5)) << 3
    ssha3.x4 rd, rs1, rs2 : rd = (((rs1+4) % 5) + 5(           rs2 % 5)) << 3
    ssha3.yx rd, rs1, rs2 : rd = (( rs2    % 5) + 5((2*rs1 + 3*rs2)% 5)) << 3
\end{isa}

% ============================================================================

\subsection{Micro-architectural Recommendations}

\todo{Macro-op fusion suggestions, side-channel considerations.}

% ============================================================================

